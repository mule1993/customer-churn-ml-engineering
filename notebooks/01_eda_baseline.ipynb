{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bZmd6IzG-1le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 1️⃣ GitHub Credentials & Repo\n",
        "# -----------------------------\n",
        "USERNAME = 'mule1993'            # GitHub username\n",
        "TOKEN = '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'  # GitHub PAT (keep secret)\n",
        "REPO_NAME = 'customer-churn-ml-engineering'\n",
        "\n",
        "REPO_URL = f'https://{USERNAME}:{TOKEN}@github.com/{USERNAME}/{REPO_NAME}.git'\n",
        "REPO_PATH = f'/content/{REPO_NAME}'\n",
        "\n",
        "# -----------------------------\n",
        "# 2️⃣ Clone or update repo\n",
        "# -----------------------------\n",
        "import os\n",
        "if not os.path.exists(REPO_PATH):\n",
        "    !git clone $REPO_URL $REPO_PATH\n",
        "else:\n",
        "    %cd $REPO_PATH\n",
        "    !git pull\n",
        "\n",
        "# -----------------------------\n",
        "# 3️⃣ Change working directory to repo root\n",
        "# -----------------------------\n",
        "%cd $REPO_PATH\n",
        "\n",
        "# -----------------------------\n",
        "# 4️⃣ Ensure __init__.py exists in all src folders\n",
        "# -----------------------------\n",
        "folders = ['src', 'src/data', 'src/features', 'src/models', 'src/utils']\n",
        "for f in folders:\n",
        "    init_file = os.path.join(REPO_PATH, f, '__init__.py')\n",
        "    if not os.path.exists(init_file):\n",
        "        open(init_file, 'a').close()\n",
        "\n",
        "# -----------------------------\n",
        "# 5️⃣ Add repo root to Python path\n",
        "# -----------------------------\n",
        "import sys\n",
        "if REPO_PATH not in sys.path:\n",
        "    sys.path.insert(0, REPO_PATH)  # insert at front to prioritize\n",
        "\n",
        "# -----------------------------\n",
        "# 6️⃣ Verify imports\n",
        "# -----------------------------\n",
        "try:\n",
        "    from src.data.loader import load_csv\n",
        "    from src.features.preprocess import prepare_features\n",
        "    from src.models.train import train_model\n",
        "    from src.models.evaluate import evaluate_model\n",
        "    from src.models.predict import load_artifacts, predict\n",
        "    print(\"✅ All modules imported successfully\")\n",
        "except ModuleNotFoundError as e:\n",
        "    print(\"❌ Module import failed:\", e)\n"
      ],
      "metadata": {
        "id": "S-rKjNbudd_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfejw4aSNG3f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ===============================\n",
        "# Phase 1: Exploration & Baseline Modeling\n",
        "# Project: Customer Churn Prediction\n",
        "# ===============================\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Setup / Imports\n",
        "# -------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/customer-churn-ml-engineering/src/data')\n",
        "import loader  # Instead of from src import data\n",
        "from loader import load_csv\n",
        "\n",
        "sys.path.append('/content/customer-churn-ml-engineering/src/features')\n",
        "import preprocess  # Instead of from src import data\n",
        "from preprocess import prepare_features\n",
        "\n",
        "sys.path.append('/content/customer-churn-ml-engineering/src/models')\n",
        "import train  # Instead of from src import data\n",
        "from train import train_model\n",
        "import evaluate\n",
        "from evaluate import evaluate_model\n",
        "\n",
        "import joblib\n",
        "\n",
        "sys.path.append('/content/customer-churn-ml-engineering/src/utils')\n",
        "import paths  # Instead of from src import data\n",
        "from paths import MODELS_DIR\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Mount Google Drive\n",
        "# -------------------------------\n",
        "# TOP\n",
        "\n",
        "# Update path according to your Drive folder\n",
        "csv_path = \"/content/drive/MyDrive/customer-churn-ml-engineering/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Load Dataset\n",
        "# -------------------------------\n",
        "\n",
        "df = load_csv(csv_path)\n",
        "df.head()\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Exploratory Data Analysis (EDA)\n",
        "# -------------------------------\n",
        "\n",
        "# Basic info\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "\n",
        "# Missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Class balance\n",
        "print(df['Churn'].value_counts(normalize=True))\n",
        "\n",
        "# Visualizations\n",
        "sns.countplot(x='Churn', data=df)\n",
        "plt.show()\n",
        "\n",
        "# Example: Histogram of numeric columns\n",
        "numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "df[numeric_cols].hist(bins=20, figsize=(12, 8))\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Preprocessing / Feature Engineering\n",
        "# -------------------------------\n",
        "\n",
        "X, y, artifacts = prepare_features(df)\n",
        "\n",
        "joblib.dump(artifacts, MODELS_DIR / \"preprocess_artifacts.joblib\")\n",
        "\n",
        "\n",
        "#joblib.dump(artifacts,\"/content/drive/MyDrive/ml_artifacts/preprocess_artifacts.joblib\")\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Baseline Models\n",
        "# -------------------------------\n",
        "# XGBoost\n",
        "#Training Module #Evaluation Module\n",
        "\n",
        "model = train_model(X_train, y_train, MODELS_DIR)\n",
        "\n",
        "\n",
        "#joblib.dump(artifacts,\"/content/drive/MyDrive/ml_artifacts/churn_model.joblib\")\n",
        "\n",
        "joblib.dump(artifacts, MODELS_DIR / \"churn_model.joblib\")\n",
        "\n",
        "metrics = evaluate_model(model, X_test, y_test)\n",
        "print(metrics[\"roc_auc\"])\n",
        "print(metrics[\"report\"])\n",
        "\n",
        "\n",
        "\n",
        "y_pred_xgb = model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Confusion matrix example\n",
        "cm = confusion_matrix(y_test, y_pred_xgb)\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Notes & Next Steps\n",
        "# -------------------------------\n",
        "# - Check feature importance\n",
        "# - Handle class imbalance if needed\n",
        "# - Prepare pipeline for Phase 2 (production-ready code)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.models.predict import load_artifacts, predict\n",
        "from src.utils.paths import MODELS_DIR\n",
        "\n",
        "model, artifacts = load_artifacts(\n",
        "    MODELS_DIR / \"churn_model.joblib\",\n",
        "    MODELS_DIR / \"preprocess_artifacts.joblib\"\n",
        ")\n",
        "\n",
        "sample = df.sample(5, random_state=42)\n",
        "preds = predict(sample, model, artifacts)\n",
        "\n",
        "preds\n"
      ],
      "metadata": {
        "id": "XVJB4SWe-ihD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}